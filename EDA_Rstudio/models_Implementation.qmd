---
title: "Implementation of models - STUDENT PERFORMANCE"
author: "Lucas Jakin"
format: html
editor: visual
---

```{r}
library(tidyverse)
library(dplyr)
library(skimr)
library(ggcorrplot)
library(gt)
library(ggplot2)

dataset <- read.csv("student_data.csv", header = T)
```

```{r}
library(reticulate)
#virtualenv_create("my-pythonImpl", python_version = "3.12")
use_virtualenv("my-pythonImpl", required = TRUE) 

virtualenv_install(envname = "my-pythonImpl", "matplotlib",ignore_installed = FALSE, pip_options = character())

#virtualenv_install(envname = "my-python2", "catboost",ignore_installed = FALSE, pip_options = character())

virtualenv_install(envname = "my-pythonImpl", "numpy",ignore_installed = FALSE, pip_options = character())

virtualenv_install(envname = "my-pythonImpl", "pandas",ignore_installed = FALSE, pip_options = character())

#virtualenv_install(envname = "my-python2", "seaborn",ignore_installed = FALSE, pip_options = character())

virtualenv_install(envname = "my-pythonImpl", "scikit-learn",ignore_installed = FALSE, pip_options = character())

#virtualenv_install(envname = "my-python2", "tensorflow",ignore_installed = FALSE, pip_options = character())
```

## HeatMap of attributes

```{python}
import pandas as pd
import numpy as np  
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.linear_model import Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error,mean_absolute_error
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import GridSearchCV
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import make_scorer
from tensorflow.keras.models import clone_model
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import KFold
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from scipy import stats

df = pd.read_csv('student_data.csv')

df['AvgGrade'] = (df['G1'] + df['G2'] + df['G3'])/3

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
for column in df.columns:
    if df[column].dtype == 'object':
        df[column] = le.fit_transform(df[column])
        
df.info()

df.to_csv("CorrelationStudent.csv", index=False)
```

### Linear Regression

> Preprocessing

```{r}
datasetTarget <- dataset %>% mutate(TotalGrade = G1 + G2 + G3,
                                      AvgGrade = (G1 + G2 + G3)/ 3)
head(datasetTarget)
write.csv(datasetTarget, "dfAvgGrade.csv", row.names = FALSE)
```

```{python}

student_df = pd.read_csv('dfAvgGrade.csv')

# Categorical attributes
cat_features = [feature for feature in student_df.columns if student_df[feature].dtype == 'O']

# Numerical attributes
num_features = [feature for feature in student_df.columns if student_df[feature].dtype != 'O']

#print(f'We have {len(num_features)} numerical features: {num_features}\n')
#print(f'We have {len(cat_features)} categorical features: {cat_features}')

fig, axs = plt.subplots(1, 2, figsize=(15, 7))
plt.subplot(121)
sns.histplot(data=student_df, x='AvgGrade', bins=30, kde=True, color='g')
plt.subplot(122)
sns.histplot(data=student_df, x='AvgGrade', kde=True, hue='sex')
plt.show()

```

```{python}
X = student_df.drop(['TotalGrade', 'AvgGrade'], axis=1)
y = student_df[['AvgGrade', 'TotalGrade']]

# Transforming the columns 
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(), cat_features)],
    remainder='passthrough'  # Leave the rest of the columns as they are
)

X = preprocessor.fit_transform(X)
```

```{python}
# Function for evaluation
def evaluate_model(true, predicted):
    mae = mean_absolute_error(true, predicted)
    mse = mean_squared_error(true, predicted)
    rmse = np.sqrt(mean_squared_error(true, predicted))
    r2_square = r2_score(true, predicted)
    return mae, rmse, r2_square
```

```{python}
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)

y_train_pred = model.predict(X_train)
y_test_pred = model.predict(X_test)
y_test

```

```{python}
pd.DataFrame({
    'Actual_TotalGrade': y_test['TotalGrade'].values,
    'Predicted_TotalGrade': y_test_pred[:, 1],
    'Actual_AvgGrade': y_test['AvgGrade'].values,
    'Predicted_AvgGrade': y_test_pred[:, 0]
})

```

```         
```
